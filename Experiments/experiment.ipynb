{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google gemini api key\n",
    "google_api_key= os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Api key found\n"
     ]
    }
   ],
   "source": [
    "if google_api_key== \"\":\n",
    "    print(\"Api key not found\")\n",
    "else:\n",
    "    print(\"Api key found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anjik\\anaconda3\\envs\\qasys\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Markdown, display # for decoration\n",
    "# from llama\n",
    "from llama_index.core import SimpleDirectoryReader # to directory reader to read data\n",
    "from llama_index.core import VectorStoreIndex # to store vectors\n",
    "from llama_index.core import ServiceContext # for keeping model, embedding together for info retrieval\n",
    "from llama_index.core import StorageContext, load_index_from_storage # to store, load embeddings\n",
    "from llama_index.embeddings.gemini import GeminiEmbedding # convert text data into Embedding\n",
    "from llama_index.llms.gemini import Gemini # model\n",
    "# from google\n",
    "import google.generativeai as genai # models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first configure/set Google_API_KEY env key as API key\n",
    "genai.configure(api_key= google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(name='models/chat-bison-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='PaLM 2 Chat (Legacy)',\n",
      "      description='A legacy text-only model optimized for chat conversations',\n",
      "      input_token_limit=4096,\n",
      "      output_token_limit=1024,\n",
      "      supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
      "      temperature=0.25,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/text-bison-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='PaLM 2 (Legacy)',\n",
      "      description='A legacy model that understands text and generates text as an output',\n",
      "      input_token_limit=8196,\n",
      "      output_token_limit=1024,\n",
      "      supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
      "      temperature=0.7,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/embedding-gecko-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Embedding Gecko',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=1024,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedText', 'countTextTokens'],\n",
      "      temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "Model(name='models/gemini-1.0-pro',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro',\n",
      "      description='The best model for scaling across a wide range of tasks',\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.9,\n",
      "      top_p=1.0,\n",
      "      top_k=1)\n",
      "Model(name='models/gemini-1.0-pro-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
      "      description=('The best model for scaling across a wide range of tasks. This is a stable '\n",
      "                   'model that supports tuning.'),\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
      "      temperature=0.9,\n",
      "      top_p=1.0,\n",
      "      top_k=1)\n",
      "Model(name='models/gemini-1.0-pro-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro Latest',\n",
      "      description=('The best model for scaling across a wide range of tasks. This is the latest '\n",
      "                   'model.'),\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.9,\n",
      "      top_p=1.0,\n",
      "      top_k=1)\n",
      "Model(name='models/gemini-1.0-pro-vision-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro Vision',\n",
      "      description='The best image understanding model to handle a broad range of applications',\n",
      "      input_token_limit=12288,\n",
      "      output_token_limit=4096,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.4,\n",
      "      top_p=1.0,\n",
      "      top_k=32)\n",
      "Model(name='models/gemini-1.5-pro-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Pro',\n",
      "      description='Mid-size multimodal model that supports up to 1 million tokens',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      top_p=0.95,\n",
      "      top_k=None)\n",
      "Model(name='models/gemini-pro',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro',\n",
      "      description='The best model for scaling across a wide range of tasks',\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.9,\n",
      "      top_p=1.0,\n",
      "      top_k=1)\n",
      "Model(name='models/gemini-pro-vision',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro Vision',\n",
      "      description='The best image understanding model to handle a broad range of applications',\n",
      "      input_token_limit=12288,\n",
      "      output_token_limit=4096,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.4,\n",
      "      top_p=1.0,\n",
      "      top_k=32)\n",
      "Model(name='models/embedding-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Embedding 001',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=2048,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedContent'],\n",
      "      temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "Model(name='models/text-embedding-004',\n",
      "      base_model_id='',\n",
      "      version='004',\n",
      "      display_name='Text Embedding 004',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=2048,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedContent'],\n",
      "      temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "Model(name='models/aqa',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Model that performs Attributed Question Answering.',\n",
      "      description=('Model trained to return answers to questions that are grounded in provided '\n",
      "                   'sources, along with estimating answerable probability.'),\n",
      "      input_token_limit=7168,\n",
      "      output_token_limit=1024,\n",
      "      supported_generation_methods=['generateAnswer'],\n",
      "      temperature=0.2,\n",
      "      top_p=1.0,\n",
      "      top_k=40)\n"
     ]
    }
   ],
   "source": [
    "# check if your API key is working or not by getting list of genai models\n",
    "for models in genai.list_models():\n",
    "    print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n"
     ]
    }
   ],
   "source": [
    "for models in genai.list_models():\n",
    "    if \"generateContent\" in models.supported_generation_methods:\n",
    "        print(models.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Ingestion\n",
    "\n",
    "-- I can do question, answering directly with llms \n",
    "-- Here, we r loading data (user provided data i.e can be database or source); use RAG sys --> Llamaindex to retrieve data \n",
    "\n",
    "load_data --> for loading all files from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 docs\n",
      "[Document(id_='c3f0e99c-4b11-46ad-8242-96575620691c', embedding=None, metadata={'file_path': 'c:\\\\Users\\\\anjik\\\\Desktop\\\\MLOPs_projects\\\\QA_System\\\\data\\\\AI.txt', 'file_name': 'AI.txt', 'file_type': 'text/plain', 'file_size': 17688, 'creation_date': '2024-04-28', 'last_modified_date': '2024-04-28'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"artificial intelligence\\r\\nArtificial intelligence (AI), the ability of a digital computer or computer-controlled robot to perform tasks commonly associated with intelligent beings. The term is frequently applied to the project of developing systems endowed with the intellectual processes characteristic of humans, such as the ability to reason, discover meaning, generalize, or learn from past experience. Since the development of the digital computer in the 1940s, it has been demonstrated that computers can be programmed to carry out very complex tasks—such as discovering proofs for mathematical theorems or playing chess—with great proficiency. Still, despite continuing advances in computer processing speed and memory capacity, there are as yet no programs that can match full human flexibility over wider domains or in tasks requiring much everyday knowledge. On the other hand, some programs have attained the performance levels of human experts and professionals in performing certain specific tasks, so that artificial intelligence in this limited sense is found in applications as diverse as medical diagnosis, computer search engines, voice or handwriting recognition, and chatbots.\\r\\n(Read Ray Kurzweil’s Britannica essay on the future of “Nonbiological Man.”)\\r\\nWhat is intelligence?\\r\\nAll but the simplest human behaviour is ascribed to intelligence, while even the most complicated insect behaviour is usually not taken as an indication of intelligence. What is the difference? Consider the behaviour of the digger wasp, Sphex ichneumoneus. When the female wasp returns to her burrow with food, she first deposits it on the threshold, checks for intruders inside her burrow, and only then, if the coast is clear, carries her food inside. The real nature of the wasp’s instinctual behaviour is revealed if the food is moved a few inches away from the entrance to her burrow while she is inside: on emerging, she will repeat the whole procedure as often as the food is displaced. Intelligence—conspicuously absent in the case of Sphex—must include the ability to adapt to new circumstances.\\r\\nPsychologists generally characterize human intelligence not by just one trait but by the combination of many diverse abilities. Research in AI has focused chiefly on the following components of intelligence: learning, reasoning, problem solving, perception, and using language.\\r\\nLearning\\r\\nThere are a number of different forms of learning as applied to artificial intelligence. The simplest is learning by trial and error. For example, a simple computer program for solving mate-in-one chess problems might try moves at random until mate is found. The program might then store the solution with the position so that the next time the computer encountered the same position it would recall the solution. This simple memorizing of individual items and procedures—known as rote learning—is relatively easy to implement on a computer. More challenging is the problem of implementing what is called generalization. Generalization involves applying past experience to analogous new situations. For example, a program that learns the past tense of regular English verbs by rote will not be able to produce the past tense of a word such as jump unless it previously had been presented with jumped, whereas a program that is able to generalize can learn the “add ed” rule and so form the past tense of jump based on experience with similar verbs.\\r\\n\\r\\n\\r\\nReasoning\\r\\nTo reason is to draw inferences appropriate to the situation. Inferences are classified as either deductive or inductive. An example of the former is, “Fred must be in either the museum or the café. He is not in the café; therefore he is in the museum,” and of the latter, “Previous accidents of this sort were caused by instrument failure; therefore this accident was caused by instrument failure.” The most significant difference between these forms of reasoning is that in the deductive case the truth of the premises guarantees the truth of the conclusion, whereas in the inductive case the truth of the premise lends support to the conclusion without giving absolute assurance. Inductive reasoning is common in science, where data are collected and tentative models are developed to describe and predict future behaviour—until the appearance of anomalous data forces the model to be revised. Deductive reasoning is common in mathematics and logic, where elaborate structures of irrefutable theorems are built up from a small set of basic axioms and rules.\\r\\nThere has been considerable success in programming computers to draw inferences. However, true reasoning involves more than just drawing inferences: it involves drawing inferences relevant to the solution of the particular task or situation. This is one of the hardest problems confronting AI.\\r\\nProblem solving\\r\\nProblem solving, particularly in artificial intelligence, may be characterized as a systematic search through a range of possible actions in order to reach some predefined goal or solution. Problem-solving methods divide into special purpose and general purpose. A special-purpose method is tailor-made for a particular problem and often exploits very specific features of the situation in which the problem is embedded. In contrast, a general-purpose method is applicable to a wide variety of problems. One general-purpose technique used in AI is means-end analysis—a step-by-step, or incremental, reduction of the difference between the current state and the final goal. The program selects actions from a list of means—in the case of a simple robot this might consist of PICKUP, PUTDOWN, MOVEFORWARD, MOVEBACK, MOVELEFT, and MOVERIGHT—until the goal is reached.\\r\\nMany diverse problems have been solved by artificial intelligence programs. Some examples are finding the winning move (or sequence of moves) in a board game, devising mathematical proofs, and manipulating “virtual objects” in a computer-generated world.\\r\\nPerception\\r\\nIn perception the environment is scanned by means of various sensory organs, real or artificial, and the scene is decomposed into separate objects in various spatial relationships. Analysis is complicated by the fact that an object may appear different depending on the angle from which it is viewed, the direction and intensity of illumination in the scene, and how much the object contrasts with the surrounding field.\\r\\nOne of the earliest systems to integrate perception and action was FREDDY, a stationary robot with a moving television eye and a pincer hand, constructed at the University of Edinburgh, Scotland, during the period 1966–73 under the direction of Donald Michie. FREDDY was able to recognize a variety of objects and could be instructed to assemble simple artifacts, such as a toy car, from a random heap of components. At present, artificial perception is sufficiently advanced to enable optical sensors to identify individuals and autonomous vehicles to drive at moderate speeds on the open road.\\r\\nLanguage\\r\\nA language is a system of signs having meaning by convention. In this sense, language need not be confined to the spoken word. Traffic signs, for example, form a mini-language, it being a matter of convention that ⚠ means “hazard ahead” in some countries. It is distinctive of languages that linguistic units possess meaning by convention, and linguistic meaning is very different from what is called natural meaning, exemplified in statements such as “Those clouds mean rain” and “The fall in pressure means the valve is malfunctioning.”\\r\\nAn important characteristic of full-fledged human languages—in contrast to birdcalls and traffic signs—is their productivity. A productive language can formulate an unlimited variety of sentences.\\r\\nLarge language models like ChatGPT can respond fluently in a human language to questions and statements. Although such models do not actually understand language as humans do but merely select words that are more probable than others, they have reached the point where their command of a language is indistinguishable from that of a normal human. What, then, is involved in genuine understanding, if even a computer that uses language like a native human speaker is not acknowledged to understand? There is no universally agreed upon answer to this difficult question.\\r\\nMethods and goals in AI\\r\\nSymbolic vs. connectionist approaches\\r\\nAI research follows two distinct, and to some extent competing, methods, the symbolic (or “top-down”) approach, and the connectionist (or “bottom-up”) approach. The top-down approach seeks to replicate intelligence by analyzing cognition independent of the biological structure of the brain, in terms of the processing of symbols—whence the symbolic label. The bottom-up approach, on the other hand, involves creating artificial neural networks in imitation of the brain’s structure—whence the connectionist label.\\r\\nTo illustrate the difference between these approaches, consider the task of building a system, equipped with an optical scanner, that recognizes the letters of the alphabet. A bottom-up approach typically involves training an artificial neural network by presenting letters to it one by one, gradually improving performance by “tuning” the network. (Tuning adjusts the responsiveness of different neural pathways to different stimuli.) In contrast, a top-down approach typically involves writing a computer program that compares each letter with geometric descriptions. Simply put, neural activities are the basis of the bottom-up approach, while symbolic descriptions are the basis of the top-down approach.\\r\\nIn The Fundamentals of Learning (1932), Edward Thorndike, a psychologist at Columbia University, New York City, first suggested that human learning consists of some unknown property of connections between neurons in the brain. In The Organization of Behavior (1949), Donald Hebb, a psychologist at McGill University, Montreal, Canada, suggested that learning specifically involves strengthening certain patterns of neural activity by increasing the probability (weight) of induced neuron firing between the associated connections. The notion of weighted connections is described in a later section, Connectionism.\\r\\nIn 1957 two vigorous advocates of symbolic AI—Allen Newell, a researcher at the RAND Corporation, Santa Monica, California, and Herbert Simon, a psychologist and computer scientist at Carnegie Mellon University, Pittsburgh, Pennsylvania—summed up the top-down approach in what they called the physical symbol system hypothesis. This hypothesis states that processing structures of symbols is sufficient, in principle, to produce artificial intelligence in a digital computer and that, moreover, human intelligence is the result of the same type of symbolic manipulations.\\r\\n\\r\\n\\r\\nDuring the 1950s and ’60s the top-down and bottom-up approaches were pursued simultaneously, and both achieved noteworthy, if limited, results. During the 1970s, however, bottom-up AI was neglected, and it was not until the 1980s that this approach again became prominent. Nowadays both approaches are followed, and both are acknowledged as facing difficulties. Symbolic techniques work in simplified realms but typically break down when confronted with the real world; meanwhile, bottom-up researchers have been unable to replicate the nervous systems of even the simplest living things. Caenorhabditis elegans, a much-studied worm, has approximately 300 neurons whose pattern of interconnections is perfectly known. Yet connectionist models have failed to mimic even this worm. Evidently, the neurons of connectionist theory are gross oversimplifications of the real thing.\\r\\nArtificial general intelligence (AGI), applied AI, and cognitive simulation\\r\\nEmploying the methods outlined above, AI research attempts to reach one of three goals: artificial general intelligence (AGI), applied AI, or cognitive simulation. AGI (also called strong AI) aims to build machines that think. The ultimate ambition of AGI is to produce a machine whose overall intellectual ability is indistinguishable from that of a human being. As is described in the section Early milestones in AI, this goal generated great interest in the 1950s and ’60s, but such optimism has given way to an appreciation of the extreme difficulties involved. To date, progress has been meagre. Some critics doubt whether research will produce even a system with the overall intellectual ability of an ant in the foreseeable future. Indeed, some researchers working in AI’s other two branches view AGI as not worth pursuing.\\r\\nApplied AI, also known as advanced information processing, aims to produce commercially viable “smart” systems—for example, “expert” medical diagnosis systems and stock-trading systems. Applied AI has enjoyed considerable success, as described in the section Expert systems.\\r\\nIn cognitive simulation, computers are used to test theories about how the human mind works—for example, theories about how people recognize faces or recall memories. Cognitive simulation is already a powerful tool in both neuroscience and cognitive psychology.\\r\\nAlan Turing and the beginning of AI\\r\\nTheoretical work\\r\\nThe earliest substantial work in the field of artificial intelligence was done in the mid-20th century by the British logician and computer pioneer Alan Mathison Turing. In 1935 Turing described an abstract computing machine consisting of a limitless memory and a scanner that moves back and forth through the memory, symbol by symbol, reading what it finds and writing further symbols. The actions of the scanner are dictated by a program of instructions that also is stored in the memory in the form of symbols. This is Turing’s stored-program concept, and implicit in it is the possibility of the machine operating on, and so modifying or improving, its own program. Turing’s conception is now known simply as the universal Turing machine. All modern computers are in essence universal Turing machines.\\r\\nDuring World War II, Turing was a leading cryptanalyst at the Government Code and Cypher School in Bletchley Park, Buckinghamshire, England. Turing could not turn to the project of building a stored-program electronic computing machine until the cessation of hostilities in Europe in 1945. Nevertheless, during the war he gave considerable thought to the issue of machine intelligence. One of Turing’s colleagues at Bletchley Park, Donald Michie (who later founded the Department of Machine Intelligence and Perception at the University of Edinburgh), later recalled that Turing often discussed how computers could learn from experience as well as solve new problems through the use of guiding principles—a process now known as heuristic problem solving.\\r\\nTuring gave quite possibly the earliest public lecture (London, 1947) to mention computer intelligence, saying, “What we want is a machine that can learn from experience,” and that the “possibility of letting the machine alter its own instructions provides the mechanism for this.” In 1948 he introduced many of the central concepts of AI in a report entitled “Intelligent Machinery.” However, Turing did not publish this paper, and many of his ideas were later reinvented by others. For instance, one of Turing’s original ideas was to train a network of artificial neurons to perform specific tasks, an approach described in the section Connectionism.\\r\\nChess\\r\\nAt Bletchley Park, Turing illustrated his ideas on machine intelligence by reference to chess—a useful source of challenging and clearly defined problems against which proposed methods for problem solving could be tested. In principle, a chess-playing computer could play by searching exhaustively through all the available moves, but in practice this is impossible because it would involve examining an astronomically large number of moves. Heuristics are necessary to guide a narrower, more discriminative search. Although Turing experimented with designing chess programs, he had to content himself with theory in the absence of a computer to run his chess program. The first true AI programs had to await the arrival of stored-program electronic digital computers.\\r\\n\\r\\n\\r\\nMore From Britannica\\r\\nWorld chess champion Garry Kasparov (left) taking a pawn in the opening minutes of a six-game, six-day chess match against IBM's Deep Blue computer in Philadelphia, February 10, 1996. Feng-hsiung Hsu (right), the principal designer of Deep Blue, keys a move into the computer. The computer, capable of computing 200 million positions per second, was powerful enough to be comparable to Kasparov in its level of play.\\r\\n(more)\\r\\nIn 1945 Turing predicted that computers would one day play very good chess, and just over 50 years later, in 1997, Deep Blue, a chess computer built by IBM (International Business Machines Corporation), beat the reigning world champion, Garry Kasparov, in a six-game match. While Turing’s prediction came true, his expectation that chess programming would contribute to the understanding of how human beings think did not. The huge improvement in computer chess since Turing’s day is attributable to advances in computer engineering rather than advances in AI: Deep Blue’s 256 parallel processors enabled it to examine 200 million possible moves per second and to look ahead as many as 14 turns of play. Many agree with Noam Chomsky, a linguist at the Massachusetts Institute of Technology (MIT), who opined that a computer beating a grandmaster at chess is about as interesting as a bulldozer winning an Olympic weightlifting competition.\\r\\n\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='4cd1e563-c5e3-4f5c-a1b7-b51e90f4ab5a', embedding=None, metadata={'file_path': 'c:\\\\Users\\\\anjik\\\\Desktop\\\\MLOPs_projects\\\\QA_System\\\\data\\\\MLDOC.txt', 'file_name': 'MLDOC.txt', 'file_type': 'text/plain', 'file_size': 21968, 'creation_date': '2024-04-25', 'last_modified_date': '2024-04-25'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='What is machine learning?\\nMachine learning is a branch of artificial intelligence (AI) and computer science which\\nfocuses on the use of data and algorithms to imitate the way that humans learn,\\ngradually improving its accuracy.\\nIBM has a rich history with machine learning. One of its own, Arthur Samuel, is credited\\nfor coining the term, “machine learning” with his research (link resides outside ibm.com)\\naround the game of checkers. Robert Nealey, the self-proclaimed checkers master,\\nplayed the game on an IBM 7094 computer in 1962, and he lost to the computer.\\nCompared to what can be done today, this feat seems trivial, but it’s considered a major\\nmilestone in the field of artificial intelligence.\\nOver the last couple of decades, the technological advances in storage and processing\\npower have enabled some innovative products based on machine learning, such as\\nNetflix’s recommendation engine and self-driving cars.\\nMachine learning is an important component of the growing field of data science.\\nThrough the use of statistical methods, algorithms are trained to make classifications or\\npredictions, and to uncover key insights in data mining projects. These insights\\nsubsequently drive decision making within applications and businesses, ideally\\nimpacting key growth metrics. As big data continues to expand and grow, the market\\ndemand for new data scientists will increase. They will be required to help identify the\\nmost relevant business questions and the data to answer them.\\nMachine learning algorithms are typically created using frameworks such as Python that\\naccelerate solution development by using platforms like TensorFlow or PyTorch.\\nNow available: watsonx.ai\\nThe all-new enterprise studio that brings together traditional machine learning along\\nwith new generative AI capabilities powered by foundation models.\\nTry watsonx.ai\\nBegin your journey to AI\\nLearn how to scale AI\\nExplore the AI Academy\\nMachine Learning vs. Deep Learning vs. Neural Networks\\nSince deep learning and machine learning tend to be used interchangeably, it’s worth\\nnoting the nuances between the two. Machine learning, deep learning, and neural\\nnetworks are all sub-fields of artificial intelligence. However, neural networks is actually\\na sub-field of machine learning, and deep learning is a sub-field of neural networks.\\nThe way in which deep learning and machine learning differ is in how each algorithm\\nlearns. \"Deep\" machine learning can use labeled datasets, also known as supervised\\nlearning, to inform its algorithm, but it doesn’t necessarily require a labeled dataset. The\\ndeep learning process can ingest unstructured data in its raw form (e.g., text or images),\\nand it can automatically determine the set of features which distinguish different\\ncategories of data from one another. This eliminates some of the human intervention\\nrequired and enables the use of large amounts of data. You can think of deep learning\\nas \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides\\noutside ibm.com).\\nClassical, or \"non-deep,\" machine learning is more dependent on human intervention to\\nlearn. Human experts determine the set of features to understand the differences\\nbetween data inputs, usually requiring more structured data to learn.\\nNeural networks, or artificial neural networks (ANNs), are comprised of node layers,\\ncontaining an input layer, one or more hidden layers, and an output layer. Each node, or\\nartificial neuron, connects to another and has an associated weight and threshold. If the\\noutput of any individual node is above the specified threshold value, that node is\\nactivated, sending data to the next layer of the network. Otherwise, no data is passed\\nalong to the next layer of the network by that node. The “deep” in deep learning is just\\nreferring to the number of layers in a neural network. A neural network that consists of\\nmore than three layers—which would be inclusive of the input and the output—can be\\nconsidered a deep learning algorithm or a deep neural network. A neural network that\\nonly has three layers is just a basic neural network.\\nDeep learning and neural networks are credited with accelerating progress in areas\\nsuch as computer vision, natural language processing, and speech recognition.\\nSee the blog post “AI vs. Machine Learning vs. Deep Learning vs. Neural Networks:\\nWhat’s the Difference?” for a closer look at how the different concepts relate.\\nRelated content\\nExplore the watsonx.ai interactive demo\\nDownload “Machine learning for Dummies”\\n- This link downloads a pdf\\nExplore Gen AI for developers\\nHow does machine learning work?\\nUC Berkeley (link resides outside ibm.com) breaks out the learning system of a\\nmachine learning algorithm into three main parts.\\nA Decision Process: In general, machine learning algorithms are used to make a\\nprediction or classification. Based on some input data, which can be labeled or\\nunlabeled, your algorithm will produce an estimate about a pattern in the data.\\nAn Error Function: An error function evaluates the prediction of the model. If\\nthere are known examples, an error function can make a comparison to assess\\nthe accuracy of the model.\\nA Model Optimization Process: If the model can fit better to the data points in the\\ntraining set, then weights are adjusted to reduce the discrepancy between the\\nknown example and the model estimate. The algorithm will repeat this iterative\\n“evaluate and optimize” process, updating weights autonomously until a\\nthreshold of accuracy has been met.\\nMachine learning methods\\nMachine learning models fall into three primary categories.\\nSupervised machine learning\\nSupervised learning, also known as supervised machine learning, is defined by its use\\nof labeled datasets to train algorithms to classify data or predict outcomes accurately.\\nAs input data is fed into the model, the model adjusts its weights until it has been fitted\\nappropriately. This occurs as part of the cross validation process to ensure that the\\nmodel avoids overfitting or underfitting. Supervised learning helps organizations solve a\\nvariety of real-world problems at scale, such as classifying spam in a separate folder\\nfrom your inbox. Some methods used in supervised learning include neural networks,\\nnaïve bayes, linear regression, logistic regression, random forest, and support vector\\nmachine (SVM).\\nUnsupervised machine learning\\nUnsupervised learning, also known as unsupervised machine learning, uses machine\\nlearning algorithms to analyze and cluster unlabeled datasets (subsets called clusters).\\nThese algorithms discover hidden patterns or data groupings without the need for\\nhuman intervention. This method’s ability to discover similarities and differences in\\ninformation make it ideal for exploratory data analysis, cross-selling strategies,\\ncustomer segmentation, and image and pattern recognition. It’s also used to reduce the\\nnumber of features in a model through the process of dimensionality reduction. Principal\\ncomponent analysis (PCA) and singular value decomposition (SVD) are two common\\napproaches for this. Other algorithms used in unsupervised learning include neural\\nnetworks, k-means clustering, and probabilistic clustering methods.\\nSemi-supervised learning\\nSemi-supervised learning offers a happy medium between supervised and\\nunsupervised learning. During training, it uses a smaller labeled data set to guide\\nclassification and feature extraction from a larger, unlabeled data set. Semi-supervised\\nlearning can solve the problem of not having enough labeled data for a supervised\\nlearning algorithm. It also helps if it’s too costly to label enough data.\\nFor a deep dive into the differences between these approaches, check out \"Supervised\\nvs. Unsupervised Learning: What\\'s the Difference?\"\\nReinforcement machine learning\\nReinforcement machine learning is a machine learning model that is similar to\\nsupervised learning, but the algorithm isn’t trained using sample data. This model learns\\nas it goes by using trial and error. A sequence of successful outcomes will be reinforced\\nto develop the best recommendation or policy for a given problem.\\nThe IBM Watson® system that won the Jeopardy! challenge in 2011 is a good example.\\nThe system used reinforcement learning to learn when to attempt an answer (or\\nquestion, as it were), which square to select on the board, and how much to\\nwager—especially on daily doubles.\\nLearn more about reinforcement learning\\nCommon machine learning algorithms\\nA number of machine learning algorithms are commonly used. These include:\\nNeural networks: Neural networks simulate the way the human brain works, with\\na huge number of linked processing nodes. Neural networks are good at\\nrecognizing patterns and play an important role in applications including natural\\nlanguage translation, image recognition, speech recognition, and image creation.\\nLinear regression: This algorithm is used to predict numerical values, based on a\\nlinear relationship between different values. For example, the technique could be\\nused to predict house prices based on historical data for the area.\\nLogistic regression: This supervised learning algorithm makes predictions for\\ncategorical response variables, such as “yes/no” answers to questions. It can be\\nused for applications such as classifying spam and quality control on a\\nproduction line.\\nClustering: Using unsupervised learning, clustering algorithms can identify\\npatterns in data so that it can be grouped. Computers can help data scientists by\\nidentifying differences between data items that humans have overlooked.\\nDecision trees: Decision trees can be used for both predicting numerical values\\n(regression) and classifying data into categories. Decision trees use a branching\\nsequence of linked decisions that can be represented with a tree diagram. One of\\nthe advantages of decision trees is that they are easy to validate and audit,\\nunlike the black box of the neural network.\\nRandom forests: In a random forest, the machine learning algorithm predicts a\\nvalue or category by combining the results from a number of decision trees.\\nAdvantages and disadvantages of machine learning algorithms\\nDepending on your budget, need for speed and precision required, each algorithm\\ntype—supervised, unsupervised, semi-supervised, or reinforcement—has its own\\nadvantages and disadvantages. For example, decision tree algorithms are used for both\\npredicting numerical values (regression problems) and classifying data into categories.\\nDecision trees use a branching sequence of linked decisions that may be represented\\nwith a tree diagram. A prime advantage of decision trees is that they are easier to\\nvalidate and audit than a neural network. The bad news is that they can be more\\nunstable than other decision predictors.\\nOverall, there are many advantages to machine learning that businesses can leverage\\nfor new efficiencies. These include machine learning identifying patterns and trends in\\nmassive volumes of data that humans might not spot at all. And this analysis requires\\nlittle human intervention: just feed in the dataset of interest and let the machine learning\\nsystem assemble and refine its own algorithms—which will continually improve with\\nmore data input over time. Customers and users can enjoy a more personalized\\nexperience as the model learns more with every experience with that person.\\nOn the downside, machine learning requires large training datasets that are accurate\\nand unbiased. GIGO is the operative factor: garbage in / garbage out. Gathering\\nsufficient data and having a system robust enough to run it might also be a drain on\\nresources. Machine learning can also be prone to error, depending on the input. With\\ntoo small a sample, the system could produce a perfectly logical algorithm that is\\ncompletely wrong or misleading. To avoid wasting budget or displeasing customers,\\norganizations should act on the answers only when there is high confidence in the\\noutput.\\nReal-world machine learning use cases\\nHere are just a few examples of machine learning you might encounter every day:\\nSpeech recognition: It is also known as automatic speech recognition (ASR), computer\\nspeech recognition, or speech-to-text, and it is a capability which uses natural language\\nprocessing (NLP) to translate human speech into a written format. Many mobile devices\\nincorporate speech recognition into their systems to conduct voice search—e.g. Siri—or\\nimprove accessibility for texting.\\nCustomer service: Online chatbots are replacing human agents along the customer\\njourney, changing the way we think about customer engagement across websites and\\nsocial media platforms. Chatbots answer frequently asked questions (FAQs) about\\ntopics such as shipping, or provide personalized advice, cross-selling products or\\nsuggesting sizes for users. Examples include virtual agents on e-commerce sites;\\nmessaging bots, using Slack and Facebook Messenger; and tasks usually done by\\nvirtual assistants and voice assistants.\\nComputer vision: This AI technology enables computers to derive meaningful\\ninformation from digital images, videos, and other visual inputs, and then take the\\nappropriate action. Powered by convolutional neural networks, computer vision has\\napplications in photo tagging on social media, radiology imaging in healthcare, and\\nself-driving cars in the automotive industry.\\nRecommendation engines: Using past consumption behavior data, AI algorithms can\\nhelp to discover data trends that can be used to develop more effective cross-selling\\nstrategies. Recommendation engines are used by online retailers to make relevant\\nproduct recommendations to customers during the checkout process.\\nRobotic process automation (RPA): Also known as software robotics, RPA uses\\nintelligent automation technologies to perform repetitive manual tasks.\\nAutomated stock trading: Designed to optimize stock portfolios, AI-driven\\nhigh-frequency trading platforms make thousands or even millions of trades per day\\nwithout human intervention.\\nFraud detection: Banks and other financial institutions can use machine learning to spot\\nsuspicious transactions. Supervised learning can train a model using information about\\nknown fraudulent transactions. Anomaly detection can identify transactions that look\\natypical and deserve further investigation.\\nChallenges of machine learning\\nAs machine learning technology has developed, it has certainly made our lives easier.\\nHowever, implementing machine learning in businesses has also raised a number of\\nethical concerns about AI technologies. Some of these include:\\nTechnological singularity\\nWhile this topic garners a lot of public attention, many researchers are not concerned\\nwith the idea of AI surpassing human intelligence in the near future. Technological\\nsingularity is also referred to as strong AI or superintelligence. Philosopher Nick\\nBostrum defines superintelligence as “any intellect that vastly outperforms the best\\nhuman brains in practically every field, including scientific creativity, general wisdom,\\nand social skills.” Despite the fact that superintelligence is not imminent in society, the\\nidea of it raises some interesting questions as we consider the use of autonomous\\nsystems, like self-driving cars. It’s unrealistic to think that a driverless car would never\\nhave an accident, but who is responsible and liable under those circumstances? Should\\nwe still develop autonomous vehicles, or do we limit this technology to\\nsemi-autonomous vehicles which help people drive safely? The jury is still out on this,\\nbut these are the types of ethical debates that are occurring as new, innovative AI\\ntechnology develops.\\nAI impact on jobs\\nWhile a lot of public perception of artificial intelligence centers around job losses, this\\nconcern should probably be reframed. With every disruptive, new technology, we see\\nthat the market demand for specific job roles shifts. For example, when we look at the\\nautomotive industry, many manufacturers, like GM, are shifting to focus on electric\\nvehicle production to align with green initiatives. The energy industry isn’t going away,\\nbut the source of energy is shifting from a fuel economy to an electric one.\\nIn a similar way, artificial intelligence will shift the demand for jobs to other areas. There\\nwill need to be individuals to help manage AI systems. There will still need to be people\\nto address more complex problems within the industries that are most likely to be\\naffected by job demand shifts, such as customer service. The biggest challenge with\\nartificial intelligence and its effect on the job market will be helping people to transition\\nto new roles that are in demand.\\nPrivacy\\nPrivacy tends to be discussed in the context of data privacy, data protection, and data\\nsecurity. These concerns have allowed policymakers to make more strides in recent\\nyears. For example, in 2016, GDPR legislation was created to protect the personal data\\nof people in the European Union and European Economic Area, giving individuals more\\ncontrol of their data. In the United States, individual states are developing policies, such\\nas the California Consumer Privacy Act (CCPA), which was introduced in 2018 and\\nrequires businesses to inform consumers about the collection of their data. Legislation\\nsuch as this has forced companies to rethink how they store and use personally\\nidentifiable information (PII). As a result, investments in security have become an\\nincreasing priority for businesses as they seek to eliminate any vulnerabilities and\\nopportunities for surveillance, hacking, and cyberattacks.\\nBias and discrimination\\nInstances of bias and discrimination across a number of machine learning systems have\\nraised many ethical questions regarding the use of artificial intelligence. How can we\\nsafeguard against bias and discrimination when the training data itself may be\\ngenerated by biased human processes? While companies typically have good\\nintentions for their automation efforts, Reuters (link resides outside ibm.com) highlights\\nsome of the unforeseen consequences of incorporating AI into hiring practices. In their\\neffort to automate and simplify a process, Amazon unintentionally discriminated against\\njob candidates by gender for technical roles, and the company ultimately had to scrap\\nthe project. Harvard Business Review (link resides outside ibm.com) has raised other\\npointed questions about the use of AI in hiring practices, such as what data you should\\nbe able to use when evaluating a candidate for a role.\\nBias and discrimination aren’t limited to the human resources function either; they can\\nbe found in a number of applications from facial recognition software to social media\\nalgorithms.\\nAs businesses become more aware of the risks with AI, they’ve also become more\\nactive in this discussion around AI ethics and values. For example, IBM has sunset its\\ngeneral purpose facial recognition and analysis products. IBM CEO Arvind Krishna\\nwrote: “IBM firmly opposes and will not condone uses of any technology, including facial\\nrecognition technology offered by other vendors, for mass surveillance, racial profiling,\\nviolations of basic human rights and freedoms, or any purpose which is not consistent\\nwith our values and Principles of Trust and Transparency.”\\nAccountability\\nSince there isn’t significant legislation to regulate AI practices, there is no real\\nenforcement mechanism to ensure that ethical AI is practiced. The current incentives for\\ncompanies to be ethical are the negative repercussions of an unethical AI system on the\\nbottom line. To fill the gap, ethical frameworks have emerged as part of a collaboration\\nbetween ethicists and researchers to govern the construction and distribution of AI\\nmodels within society. However, at the moment, these only serve to guide. Some\\nresearch (link resides outside ibm.com) shows that the combination of distributed\\nresponsibility and a lack of foresight into potential consequences aren’t conducive to\\npreventing harm to society.\\nRead more about IBM\\'s position on AI Ethics\\nHow to choose the right AI platform for machine learning\\nSelecting a platform can be a challenging process, as the wrong system can drive up\\ncosts, or limit the use of other valuable tools or technologies. When reviewing multiple\\nvendors to select an AI platform, there is often a tendency to think that more features =\\na better system. Maybe so, but reviewers should start by thinking through what the AI\\nplatform will be doing for their organization. What machine learning capabilities need to\\nbe delivered and what features are important to accomplish them? One missing feature\\nmight doom the usefulness of an entire system. Here are some features to consider.\\nMLOps capabilities. Does the system have:\\na unified interface for ease of management?\\nautomated machine learning tools for faster model creation with low-code\\nand no-code functionality?\\ndecision optimization to streamline the selection and deployment of\\noptimization models?\\nvisual modeling to combine visual data science with open-source libraries\\nand notebook-based interfaces on a unified data and AI studio?\\nautomated development for beginners to get started quickly and more\\nadvanced data scientists to experiment?\\nsynthetic data generator as an alternative or supplement to real-world data\\nwhen real-world data is not readily available?\\nGenerative AI capabilities. Does the system have:\\na content generator that can generate text, images and other content\\nbased on the data it was trained on?\\nautomated classification to read and classify written input, such as\\nevaluating and sorting customer complaints or reviewing customer\\nfeedback sentiment?\\na summary generator that can transform dense text into a high-quality\\nsummary, capture key points from financial reports, and generate meeting\\ntranscriptions?\\na data extraction capability to sort through complex details and quickly pull\\nthe necessary information from large documents?', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='985d7003-e290-440f-8688-0d0fb81d2200', embedding=None, metadata={'file_path': 'c:\\\\Users\\\\anjik\\\\Desktop\\\\MLOPs_projects\\\\QA_System\\\\data\\\\mlflow_airflow.txt', 'file_name': 'mlflow_airflow.txt', 'file_type': 'text/plain', 'file_size': 3321, 'creation_date': '2024-04-28', 'last_modified_date': '2024-04-28'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='MLflow\\r\\nOpen source platform provides tools and simplifying processes to streamline the ML lifecycle (dev, deployment) and foster collaboration among ML practitioners.\\r\\n\\r\\nComponents\\r\\n\\r\\nMLflow Tracking: provides API & UI to log parameters, code versions, metrics, artifacts during ML process. This centralized repository stores parameters, metrics, artifacts, data, env configs, giving teams insight into their model’s evolution over time. Tracking facilitates logging of results either to localfiles or server, allows to compare multiple runs/experiments across different users\\r\\nModel Registry: systematic approach to model management\\r\\nCentralized model store, APIs, UIs; allows to collaboratively manage MLflow model’s life cycle i.e model lineage, versioning, tagging, aliasing,annotations\\r\\nEvaluate: designed for in depth model analysis, facilitate model comparison i.e traditional ML algorithms or cutting edge LLMs\\r\\nPrompt Engineering UI: provides space for prompt experimentation, refinement, evaluation, testing, and deployment.\\r\\nRecipes: Serving as a guide for structuring ML projects\\r\\nProjects: MLflow Projects standardize the packaging of ML code, workflows, and artifacts, akin to an executable. \\r\\nEach project, be it a directory with code or a Git repository, employs a descriptor or convention to define its dependencies and execution method\\r\\n\\r\\n\\r\\nAirflow\\r\\nopen source platform for orchestrating and scheduling, automating complex workflows (create and monitor workflow schedules)\\r\\nWorkflow: ~ETL (data extraction, transformation, loading: Data Eng; data ingestion, validation, transformation, training … Data Sci)\\r\\nAirflow \\r\\norchestrates various steps of your pipeline/ workflow\\r\\nAirflow → developed by Airbnd in 2014 as data management, orchestrating workflows makes data eng effective\\r\\nuser friendly UI, higher scalability, easier scheduling workflows\\r\\nAIRFLOW -> best data orchestration tool for data eng’s\\r\\n\\r\\nBest Use-cases:\\r\\nETL for data eng, data warehouse, data analysis\\r\\nAutomates—> extracting data from various sources, transforms data and load into data warehouse. Maintains accuracy of data, to go tool for managing automation of complex datasets ETL\\r\\n\\r\\nBenefits: \\r\\nhigher flexibility (can optimize workflows to your need), scalability (simple to petabyte data), operators and sensors, plugin ecosys, community support (popular). \\r\\nRobust workflow automation tool → orchestrates data pipelines very easily\\r\\n\\r\\nSetup airflow in windows\\r\\nNeed Docker Desktop, VSCode in your pc\\r\\nCreate project folder in vscode\\r\\nDownload file: https:airflow.apache.org/docs/apache-airflow/2.5.1/docker-compose.yaml\\r\\nCreate .env folder, add\\r\\nAIRFLOW_IMAGE_NAME= apache/airflow:2.4.2\\r\\nAIRFLOW_UID=50000\\r\\nOpen terminal → docker-compose up -d (sets up airflow automatically)\\r\\nLocalhost:8080 -> airflow window -> username: admin, password: admin\\r\\nOpen terminal —> type this\\r\\ndocker-compose run airflow-scheduler airflow users create --username adminn --password admin --firstname Admin --lastname User --role Admin --email admin@superhero.org\\r\\n\\r\\nComponents of Airflow\\r\\nDAGs: Directed Acyclic Graphs→ mathematical structures represent workflow as a collection of tasks connected by dependencies. DAGs ensure tasks execute in a specific order, with no circular dependencies or loops.\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]\n"
     ]
    }
   ],
   "source": [
    "# create data loader obj\n",
    "reader= SimpleDirectoryReader(input_dir= \"../data\", required_exts=[\".txt\"])\n",
    "# load method -> \n",
    "documents= reader.load_data()\n",
    "print(f\"Loaded {len(documents)} docs\")\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anjik\\AppData\\Local\\Temp\\ipykernel_16844\\4290519884.py:8: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context= ServiceContext.from_defaults(llm= llm_model,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ServiceContext(llm_predictor=LLMPredictor(system_prompt=None, query_wrapper_prompt=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>), prompt_helper=PromptHelper(context_window=32768, num_output=2048, chunk_overlap_ratio=0.1, chunk_size_limit=None, separator=' '), embed_model=GeminiEmbedding(model_name='models/embedding-001', embed_batch_size=10, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x00000224B0926280>, title=None, task_type='retrieval_document'), transformations=[SentenceSplitter(include_metadata=True, include_prev_next_rel=True, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x00000224B0926280>, id_func=<function default_id_func at 0x00000224AC046940>, chunk_size=800, chunk_overlap=20, separator=' ', paragraph_separator='\\n\\n\\n', secondary_chunking_regex='[^,.;。？！]+[,.;。？！]?')], llama_logger=<llama_index.core.service_context_elements.llama_logger.LlamaLogger object at 0x00000224B0819EE0>, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x00000224B0926280>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load embedding model --> Gemini model --> i/p text; o/p text\n",
    "gemini_embed_model= GeminiEmbedding(model_name= \"models/embedding-001\")\n",
    "\n",
    "# load llm Gemini model using ----> llama_index.llms.gemini or google.generative as genai also\n",
    "llm_model= Gemini(api_key= google_api_key, model_name=\"models/gemini-pro\")\n",
    "\n",
    "# configure ServiceContext (class is a container --> objects for configuring every index, query i.e llm model, embedding model, chunnk size etc) \n",
    "service_context= ServiceContext.from_defaults(llm= llm_model,\n",
    "    embed_model= gemini_embed_model,\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=20)\n",
    "\n",
    "service_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x224b09b5fa0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create vector index\n",
    "index= VectorStoreIndex.from_documents(documents= documents, service_context=service_context)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the vector embedding index to local database (storage inside Experiments dir---> have all info, metainfo)\n",
    "index.storage_context.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning is a branch of artificial intelligence (AI) and computer science which focuses on the use of data and algorithms to imitate the way that humans learn, gradually improving its accuracy.\n"
     ]
    }
   ],
   "source": [
    "query_engine= index.as_query_engine()\n",
    "response=query_engine.query(\"What is machine learning?\")\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The development of the digital computer in the 1940s demonstrated that computers could be programmed to carry out very complex tasks with great proficiency. However, despite continuing advances in computer processing speed and memory capacity, there are as yet no programs that can match full human flexibility over wider domains or in tasks requiring much everyday knowledge. On the other hand, some programs have attained the performance levels of human experts and professionals in performing certain specific tasks, so that artificial intelligence in this limited sense is found in applications as diverse as medical diagnosis, computer search engines, voice or handwriting recognition, and chatbots.\n"
     ]
    }
   ],
   "source": [
    "query_engine= index.as_query_engine()\n",
    "response= query_engine.query(\"Give me history of Artificial intelligence\")\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning is a branch of artificial intelligence (AI) and computer science which focuses on the use of data and algorithms to imitate the way that humans learn, gradually improving its accuracy.\n"
     ]
    }
   ],
   "source": [
    "query_engine= index.as_query_engine()\n",
    "response= query_engine.query(\"What is machine learning, artificial intelligence?\")\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Supervised Machine Learning | Unsupervised Machine Learning |\n",
      "|---|---|\n",
      "| Uses labeled datasets | Uses unlabeled datasets |\n",
      "| Algorithms are trained to classify data or predict outcomes | Algorithms discover hidden patterns or data groupings |\n",
      "| Requires human intervention to label data | Does not require human intervention to label data |\n",
      "| Examples: neural networks, naïve bayes, linear regression, logistic regression, random forest, support vector machine (SVM) | Examples: neural networks, k-means clustering, probabilistic clustering methods |\n"
     ]
    }
   ],
   "source": [
    "query_engine= index.as_query_engine()\n",
    "response= query_engine.query(\"Difference between supervised and unsupervised machine learning in tablular farmat\")\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Tracking, Model Registry, Evaluate, Prompt Engineering UI, Recipes, Projects\n"
     ]
    }
   ],
   "source": [
    "query_engine= index.as_query_engine()\n",
    "response= query_engine.query(\"What are mlflow components\")\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided context does not mention Malleswari Gelli, so I cannot answer this question from the provided context.\n"
     ]
    }
   ],
   "source": [
    "query_engine= index.as_query_engine()\n",
    "response= query_engine.query(\"Who is Malleswari Gelli\")\n",
    "print(response.response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qasys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
